?between
??between
source('D:/Github/R_Harvard/ConfidenceInterval.R', echo=TRUE)
source('D:/Github/R_Harvard/ConfidenceInterval.R', echo=TRUE)
source('D:/Github/R_Harvard/ConfidenceInterval.R', echo=TRUE)
source('D:/Github/R_Harvard/ConfidenceInterval.R', echo=TRUE)
source('D:/Github/R_Harvard/ConfidenceInterval.R', echo=TRUE)
source('D:/Github/R_Harvard/ConfidenceInterval.R', echo=TRUE)
source('D:/Github/R_Harvard/ConfidenceInterval.R', echo=TRUE)
source('D:/Github/R_Harvard/ConfidenceInterval.R', echo=TRUE)
install.packages("dslab")
install.packages("dslabs")
library(dslabs)
data("polls_us_election_2016")
polls <- filter(polls_us_election_2016, polls_us_election_2016$enddate>="2016-10-31")
polls
polls_us_election_2016$enddate
class(polls_us_election_2016$enddate)
polls <- filter(polls_us_election_2016, polls_us_election_2016$enddate>=2016-10-31)
polls <- filter(polls_us_election_2016, polls_us_election_2016$enddate>=as.Date("2016-10-31"))
polls
polls <- filter(polls_us_election_2016, polls_us_election_2016$enddate>=as.Date("2016-31-10"))
polls
test<- as.Date("2016-11-4")
test>as.Date("2016-10-12")
polls <- filter(polls_us_election_2016, as.Date(polls_us_election_2016$enddate)>=as.Date("2016-10-31"))
polls
test>=as.Date("2016-10-12")
?filter
polls <- filter(polls_us_election_2016$enddate>=as.Date("2016-10-31"))
polls <- filter(polls_us_election_2016$enddate, polls_us_election_2016$enddate>=as.Date("2016-10-31"))
polls
polls <- filter(polls_us_election_2016,enddate>=as.Date("2016-10-31"))
install.packages("titanic")
c(test, test+1)
date_test<-c(test, test+1)
date_test>=as.Date("2016-10-12")
polls_us_election_2016$enddate>= as.Date("2016-10-31")
filter(polls_us_election_2016, polls_us_election_2016$enddate>= as.Date("2016-10-31"))
x <- 1:100
filter(x, x>5)
filter(x, 5)
filter(x, >5)
filter(polls_us_election_2016, enddate>= as.Date("2016-10-31"))
filter(polls_us_election_2016)
polls <- polls_us_election_2016%>%
filter(enddate>=as.Date("2016-10-31"))
install.packages("tidyverse")
polls <- polls_us_election_2016%>%
filter(enddate>=as.Date("2016-10-31"))
library(dplyr)
polls <- polls_us_election_2016%>%
filter(enddate>=as.Date("2016-10-31"))
polls
polls <- polls_us_election_2016%>%
filter(enddate>=as.Date("2016-10-31"), state=="U.S.")
polls
names(polls)
nrow(polls)
polls$pollster
polls$rawpoll_clinton
?qnorm
?group_by
?filter
?n
source('D:/Github/R_Harvard/PollAggregators.R', echo=TRUE)
?summarize
??summarize
library("dplyr")
?summarize
source('D:/Github/R_Harvard/PollAggregators.R', echo=TRUE)
round(moe*100,1)
source('D:/Github/R_Harvard/PollAggregators.R', echo=TRUE)
source('D:/Github/R_Harvard/PollAggregators.R', echo=TRUE)
source('D:/Github/R_Harvard/PollAggregators.R', echo=TRUE)
source('D:/Github/R_Harvard/PollsterBias.R', echo=TRUE)
??ggplot
install.packages("ggplot2")
library("ggplot2")
source('D:/Github/R_Harvard/PollsterBias.R', echo=TRUE)
source('D:/Github/R_Harvard/PollsterBias.R', echo=TRUE)
?between
?qnorm
getwd()
system.file("extdata", package="dslabs")
path <-system.file("extdata", package="dslabs")
list.files(path = )
filename <- "murders.csv"
fullpath <- file.path(path, filename)
fullpath
file.copy(fullpath, getwd())
list.files(getwd())
source('D:/Github/R_Harvard/PathAndDirs.R', echo=TRUE)
fullpath
source('D:/Github/R_Harvard/readrNreadxl.R', echo=TRUE)
class(dat3$abb)
library(dslabs)
library(tidyverse)
library(readxl)
#inspect the first 3 lines
read_lines("murders.csv", n_max = 3)
# read file in CSV format
dat <- read.csv(filename)
#read using full path
dat <- read.csv(fullpath)
#Ex:
path <- system.file("extdata", package = "dslabs")
files <- list.files(path)
files
filename <- "murders.csv"
filename1 <- "life-expectancy-and-fertility-two-countries-example.csv"
filename2 <- "fertility-two-countries-example.csv"
dat=read.csv(file.path(path, filename))
dat1=read.csv(file.path(path, filename1))
dat2=read.csv(file.path(path, filename2))
dat3 <- read.csv(filename, stringsAsFactors = FALSE)
class(dat3$abb)
file.remove(tmp_filename)
source('~/.active-rstudio-document', echo=TRUE)
library(tidyverse)
source('D:/Github/R_Harvard/DataImportAssessment.R', echo=TRUE)
source('D:/Github/R_Harvard/DataImportAssessment.R', echo=TRUE)
source('D:/Github/R_Harvard/DataImportAssessment.R', echo=TRUE)
source('D:/Github/R_Harvard/DataImportAssessment.R', echo=TRUE)
source('D:/Github/R_Harvard/DataImportAssessment.R', echo=TRUE)
source('D:/Github/R_Harvard/ReshapeData.R', echo=TRUE)
source('D:/Github/R_Harvard/ReshapeData.R', echo=TRUE)
source('D:/Github/R_Harvard/ReshapeData.R', echo=TRUE)
source('D:/Github/R_Harvard/ReshapeData.R', echo=TRUE)
source('D:/Github/R_Harvard/ReshapeData.R', echo=TRUE)
source('D:/Github/R_Harvard/SepNUnite.R', echo=TRUE)
?head
source('D:/Github/R_Harvard/SepNUnite.R', echo=TRUE)
source('D:/Github/R_Harvard/Binding.R', echo=TRUE)
?tab
??tab
source('D:/Github/R_Harvard/Binding.R', echo=TRUE)
install.packages("ggrepel")
source('D:/Github/R_Harvard/SetOperators.R', echo=TRUE)
source('D:/Github/R_Harvard/SetOperators.R', echo=TRUE)
source('D:/Github/R_Harvard/SetOperators.R', echo=TRUE)
source('D:/Github/R_Harvard/SetOperators.R', echo=TRUE)
source('D:/Github/R_Harvard/SetOperators.R', echo=TRUE)
source('D:/Github/R_Harvard/SetOperators.R', echo=TRUE)
source('D:/Github/R_Harvard/SetOperators.R', echo=TRUE)
library(Lahman)
top <- Batting %>%
filter(yearID == 2016) %>%
arrange(desc(HR)) %>%    # arrange by descending HR count
slice(1:10)    # take entries 1-10
top %>% as_tibble()
install.packages("Lahman")
library(Lahman)
top <- Batting %>%
filter(yearID == 2016) %>%
arrange(desc(HR)) %>%    # arrange by descending HR count
slice(1:10)    # take entries 1-10
top %>% as_tibble()
Master.as_tibble()
Master
Master%>%as_tibble()
top_name <- top%>%
l
Salaries%>% as_tibble()
as_tibble(AwardsPlayers)
top_name<- top %>%
left_join(Master)%>%
select(playerID, nameFirst, nameLast, HR)
as_tibble(top_name)
top_name%>%
left_join(AwardsPlayers)%>%
as_tibble()
q7<-top_name%>%
left_join(AwardsPlayers)%>%
as_tibble()
q7%>%
setdiff(AwardsPlayers)%>%
sum(awardID)
intersect(top_name,AwardsPlayers)%>%
l
setdiff(top_name, AwardsPlayers)
sum(AwardsPlayers$awardID)
means(AwardsPlayers$awardID)
mean(AwardsPlayers$awardID)
AwardsPlayers%>%
l
sum(NA %in% AwardsPlayers$awardID)
sum(is.na(AwardsPlayers$awardID))
is.na(AwardsPlayers$awardID)
993-8
AwardsPlayers<- AwardsPlayers%>%
filter(yearID==2016)
top_name%>%
+ left_join(AwardsPlayers)%>%
+ as_tibble()
top_name%>%
left_join(AwardsPlayers)%>%
as_tibble()
top_name
setdiff(AwardsPlayers, top_name)
full <- full_join(AwardsPlayers,top_name)
full
part <- left_join(top_name, AwardsPlayers)
setdiff(full, part)
ans<-setdiff(full, part)
duplicate(ans$playerID)
duplicated(ans$playerID)
sum(duplicated(ans$playerID))
install.packages("rvest")
install.packages("rvest")
install.packages("rvest")
library(rvest)
source('D:/Github/R_Harvard/WebScraping.R', echo=TRUE)
source('D:/Github/R_Harvard/WebScraping.R', echo=TRUE)
source('D:/Github/R_Harvard/GetRecipe.R', echo=TRUE)
source('D:/Github/R_Harvard/GetRecipe.R', echo=TRUE)
url <- "https://web.archive.org/web/20181024132313/http://www.stevetheump.com/Payrolls.htm"
h <- read_html(url)
nodes <- html_nodes(h, "table")
html_text(nodes[[8]])
head(html_table(node[[1]]))
head(html_table(nodes[[1]]))
head(html_table(nodes[[2]]))
head(html_table(nodes[[3]]))
head(html_table(nodes[[-1]]))
head(html_table(nodes[[21]]))
head(html_table(nodes[[22]]))
tab_1<-html_table(nodes[[10]])
tab_2<-html_table(nodes[[19]])
tab_1
head(tab_2)
tab_1 <- tab_1%>%
select(-No.)
library(tidyverse)
tab_1 <- tab_1%>%
select(-No.)
tab_1 <- tab_1%>%
select(-X1)
head(tab_1)
tab_1 <- tab_1[-1]
head(tab_1)
tab_1<-html_table(nodes[[10]])
tab_1 <- tab_1%>%
select(-X1)
tab_1[-1,]
tab_1<- tab_1[-1,]%>%
setNames(c("Team", "Payroll", "Average"))
head(tab_1)
tab_2<- tab_2[-1,]%>%
setNames(c("Team", "Payroll", "Average"))
head(tab_2)
full <- full_join(tab_1, tab_2)
nrow(full)
head(full)
full
tab_1
tab_2
setdiff(tab_1, tab_2)
setequal(tab_1, tab_2)
?full_join
full <- full_join(tab_1, tab_2, Team)
full <- full_join(tab_1, tab_2, tab_1$Team)
full <-tab_1%>% full_join(tab_2, Team)
full <-tab_1%>% full_join(tab_2, Team)
tab_1%>%
full_join(tab_2, Team)
full_join(tab_2, "Team")
tab_1%>%
full_join(tab_2, "Team")
url <- "https://en.wikipedia.org/w/index.php?title=Opinion_polling_for_the_United_Kingdom_European_Union_membership_referendum&oldid=896735054"
h <- read_html(url)
tab <- h %>% html_nodes("table")
tab
tab[[20]]
tab[[21]]
length(tab)
html_table(tab[[1]])
html_table(tab[[1]], fill = T)
head(html_table(tab[[1]], fill = T))
head(html_table(tab[[2]], fill = T))
head(html_table(tab[[3]], fill = T))
head(html_table(tab[[4]], fill = T))
head(html_table(tab[[5]], fill = T))
"5\'10\""
cat("5\'10\"")
source('D:/Github/R_Harvard/CaseStudy1.R', echo=TRUE)
source('D:/Github/R_Harvard/CaseStudy1.R', echo=TRUE)
source('D:/Github/R_Harvard/CaseStudy1.R', echo=TRUE)
source('D:/Github/R_Harvard/CaseStudy2.R', echo=TRUE)
source('D:/Github/R_Harvard/CaseStudy2.R', echo=TRUE)
source('D:/Github/R_Harvard/CaseStudy2.R', echo=TRUE)
source('D:/Github/R_Harvard/Regex.R', echo=TRUE)
source('D:/Github/R_Harvard/Regex.R', echo=TRUE)
source('D:/Github/R_Harvard/Regex.R', echo=TRUE)
install.packages("htmlwidgets")
source('D:/Github/R_Harvard/Regex.R', echo=TRUE)
source('D:/Github/R_Harvard/CharClassesAnchorNQuantifier.R', echo=TRUE)
source('D:/Github/R_Harvard/SearchNReplace.R', echo=TRUE)
source('D:/Github/R_Harvard/SearchNReplace.R', echo=TRUE)
source('D:/Github/R_Harvard/SearchNReplace.R', echo=TRUE)
source('D:/Github/R_Harvard/Regex.R', echo=TRUE)
source('D:/Github/R_Harvard/CharClassesAnchorNQuantifier.R', echo=TRUE)
source('D:/Github/R_Harvard/SearchNReplace.R', echo=TRUE)
source('D:/Github/R_Harvard/GroupRegex.R', echo=TRUE)
str_detect(s, pattern_without_groups)
# demonstrate difference between str_match and str_extract
str_match(s, pattern_with_groups)
str_extract(s, pattern_with_groups)
source('D:/Github/R_Harvard/GroupRegex.R', echo=TRUE)
source('D:/Github/R_Harvard/TestingNImproving.R', echo=TRUE)
source('D:/Github/R_Harvard/TestingNImproving.R', echo=TRUE)
source('D:/Github/R_Harvard/TestingNImproving.R', echo=TRUE)
?str_detect
?str_view_all
source('D:/Github/R_Harvard/SepwRegex.R', echo=TRUE)
source('D:/Github/R_Harvard/GroupNQuantifiers.R', echo=TRUE)
source('D:/Github/R_Harvard/GroupNQuantifiers.R', echo=TRUE)
library(purrr)
?map
source('D:/Github/R_Harvard/StringSplitting.R', echo=TRUE)
source('D:/Github/R_Harvard/StringSplitting.R', echo=TRUE)
source('D:/Github/R_Harvard/StringSplitting.R', echo=TRUE)
?download.file
source('D:/Github/R_Harvard/ExtractPDF.R', echo=TRUE)
install.packages("pdftools")
source('D:/Github/R_Harvard/ExtractPDF.R', echo=TRUE)
head(raw_data_research_funding_rates)
raw_data_research_funding_rates <- txt[2]
head(raw_data_research_funding_rates)
tab <- str_split(raw_data_research_funding_rates, "\n")
tab <- tab[[1]]
head(tab)
the_names_1 <- tab[3]
the_names_2 <- tab[4]
the_names_1<- the_names_1%>%
str_trim()%>%
str_replace_all(",\\s.","")%>%
str_split("\\s{2,}", simplify = T)
the_names_1
the_names_2
the_names_2<- the_names_2%>%
str_trim()%>%
str_split("\\s+", simplify = T)
the_names_2
the_names_2
tmp_names <- str_c(rep(the_names_1, each=3), the_names_2[-1], sep="_")
the_names<- c(the_names_2[1], tmp_names)%>%
str_to_lower()%>%
str_replace_all("\\s", "_")
the_names
new_research_funding_rates <- tab[6:14] %>%
str_trim %>%
str_split("\\s{2,}", simplify = TRUE) %>%
data.frame(stringsAsFactors = FALSE) %>%
setNames(the_names) %>%
mutate_at(-1, parse_number)
new_research_funding_rates %>% head()
the_names
data(new_research_funding_rates)
new_research_funding_rates <- tab[6:14] %>%
str_trim %>%
str_split("\\s{2,}", simplify = TRUE) %>%
data.frame(stringsAsFactors = FALSE) %>%
setNames(the_names) %>%
mutate_at(-1, parse_number)
source('D:/Github/R_Harvard/Recoding.R', echo=TRUE)
source('D:/Github/R_Harvard/Recoding.R', echo=TRUE)
source('D:/Github/R_Harvard/Recoding.R', echo=TRUE)
?unnest
library(rvest)
library(tidyverse)
library(stringr)
url <- "https://en.wikipedia.org/w/index.php?title=Opinion_polling_for_the_United_Kingdom_European_Union_membership_referendum&oldid=896735054"
tab <- read_html(url) %>% html_nodes("table")
polls <- tab[[5]] %>% html_table(fill = TRUE)
polls%>% head()
polls %>%
set_names(c("dates", "remain", "leave", "undecided", "lead", "samplesize", "pollster", "poll_type", "notes"))%>%
filter(str_detect(remain,"%"))
polls <-polls %>%
set_names(c("dates", "remain", "leave", "undecided", "lead", "samplesize", "pollster", "poll_type", "notes"))%>%
filter(str_detect(remain,"%"))
?as.numeric
install.packages("lubridate")
install.packages("lubridate")
source('D:/Github/R_Harvard/DatesNTimes.R', echo=TRUE)
# lubridate: the tidyverse date package
library(lubridate)
# lubridate: the tidyverse date package
library(lubridate)
# select some random dates from polls
set.seed(2)
dates <- sample(polls_us_election_2016$startdate, 10) %>% sort
dates
# extract month, day, year from date strings
data.frame(date = dates,
month = month(dates),
day = day(dates),
year = year(dates))
# ymd works on mixed date styles
x <- c(20090101, "2009-01-02", "2009 01 03", "2009-1-4",
"2009-1, 5", "Created on 2009 1 6", "200901 !!! 07")
ymd(x)
# different parsers extract year, month and day in different orders
x <- "09/01/02"
ymd(x)
mdy(x)
ydm(x)
myd(x)
dmy(x)
dym(x)
now()    # current time in your time zone
now("GMT")    # current time in GMT
now() %>% hour()    # current hour
now() %>% minute()    # current minute
now() %>% second()    # current second
now() %>% second()    # current second
# parse time
x <- c("12:34:56")
hms(x)
#parse datetime
x <- "Nov/2/2012 12:34:56"
mdy_hms(x)
install.packages("tidytext")
data("brexit_polls")
nrow(filter(month(brexit_polls$startdate)==4))
nrow(filter(brexit_polls,month(startdate)==4))
?round_date
round_date(brexit_polls$enddate== ymd("16/06/12"), unit = "week")
round_date(brexit_polls$enddate, unit = "week")
sum(round_date(brexit_polls$enddate, unit = "week")==ymd("16/06/12"))
?weekdays
weekdays(brexit_polls$enddate)
weekdays(brexit_polls$enddate)%>%
summarise("Monday")
weekdays(brexit_polls$enddate)%>%
summarise()
weekdays(brexit_polls$enddate)%>%
summarise()
?summarise
summarise()
weekdays(brexit_polls$enddate)%>%
summarise(Monday = n())
count(weekdays(brexit_polls$enddate),"Monday")
sum(weekdays(brexit_polls$enddate)=="Monday")
sum(weekdays(brexit_polls$enddate)=="Tuesday")
sum(weekdays(brexit_polls$enddate)=="Wednessday")
sum(weekdays(brexit_polls$enddate)=="Wednesday")
sum(weekdays(brexit_polls$enddate)=="Thursday")
sum(weekdays(brexit_polls$enddate)=="Friday")
sum(weekdays(brexit_polls$enddate)=="Saturday")
sum(weekdays(brexit_polls$enddate)=="Sunday")
data("movielens")
date_movie <- as_datetime(movielens$timestamp)
date_movie
table(year(date_movie))
table(hour(date_movie))
install.packages("gutenbergr")
gutenbergr_metadata
library(tidyverse)
library(gutenbergr)
library(tidytext)
options(digits = 3)
gutenberg_metadata
sum(str_detect(gutenberg_metadata$title, "Pride and Prejudice"))
str_detect(gutenberg_metadata$title, "Pride and Prejudice")
head(gutenberg_metadata$title)
gutenberg_metadata$title
file.path("D:\Github\R_Harvard\KPMG\KPMG_VI_New_raw_data_update_final.xlsx")
path <- system.file("D:\Github\R_Harvard\KPMG\KPMG_VI_New_raw_data_update_final.xlsx")
setwd("D:")
getwd()
setwd("D:/Github/R_Harvard")
getwd()
path <- system.file("KPMG/KPMG_VI_New_raw_data_update_final.xlsx")
setwd("D:/Github/R_Harvard/KPMG")
library(tidyverse)
library(readxl)
?system.file
filename <- system.file("KPMG_VI_New_raw_data_update_final.xlsx")
data <- read_excel(filename)
data <- read_excel(file.path(filename))
getwd()
filename
filename <- "KPMG_VI_New_raw_data_update_final.xlsx"
data <- read_excel(file.path(path, filename))
data <- read_excel(filename)
?read_excel
data_page_2 <- read_excel(filename, 2)
data_page_3<- read_excel(filename, 3)
transaction_data <- read_excel(filename, 2)
newcustomerlist_data<- read_excel(filename, 3)
customerdemo_data<- read_excel(filename, 4)
customeraddress_data <- read_excel(filename, 5)
?is.na
head(transaction_data)
head(newcustomerlist_data)
head(customerdemo_data)
head(customeraddress_data)
